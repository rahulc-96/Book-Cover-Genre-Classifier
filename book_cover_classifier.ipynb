{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "book-cover-test.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WD-9anfgY50c",
        "colab_type": "text"
      },
      "source": [
        "**Loading Datasets from file system**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "V9clr-Yq96rC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "import numpy as np\n",
        "import pandas as pd \n",
        "import os\n",
        "from keras.preprocessing.image import load_img\n",
        "from keras.preprocessing.image import img_to_array\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "import matplotlib.pyplot as pyplot\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.optimizers import SGD,rmsprop\n",
        "from random import randrange\n",
        "\n",
        "#filtering out different book categories\n",
        "class_names=[]\n",
        "for root, dirname, filenames in os.walk('book-covers'):\n",
        "    for className in dirname:\n",
        "        class_names.append(className)\n",
        "#print(class_names)\n",
        "\n",
        "class_names=class_names[0:5]\n",
        "print(class_names)\n",
        "\n",
        "# Mappong between category->List of Files in that category\n",
        "filesAndClassMap={}\n",
        "for class_name in class_names:\n",
        "    for _,_,filenames in os.walk('book-covers/'+class_name):\n",
        "        filesAndClassMap[class_name]=filenames;\n",
        "\n",
        "\n",
        "#Loading Image Files as arrays of shape 224*224*3\n",
        "def load_image(filename):\n",
        "    img = load_img(filename, target_size=(224, 224))\n",
        "    img = img_to_array(img)\n",
        "    img = img.reshape(1, 224, 224, 3)\n",
        "    img = img.astype('float32')\n",
        "    img = img / 255.0\n",
        "    return img\n",
        "\n",
        "#To check if a list is empty or not\n",
        "def isEmpty(collection)\n",
        "    if not collection:\n",
        "              return True\n",
        "    else:\n",
        "              return False\n",
        "train_images=[]\n",
        "train_labels=[]\n",
        "\n",
        "#Loading Images from Random classes to generate a dataset file including all book covers and label file with corresponding labels\n",
        "def load_images():\n",
        "    while(len(class_names)!=0):\n",
        "        random_index = randrange(len(class_names))\n",
        "        random_className = class_names[random_index]\n",
        "        if not isEmpty(filesAndClassMap[random_className]):\n",
        "            file=filesAndClassMap[random_className][0]\n",
        "            if(file.split(\".\")[1]==\"csv\"):\n",
        "                filesAndClassMap[random_className].pop(0)\n",
        "            if(file.split(\".\")[1]==\"jpg\"):\n",
        "                train_images.extend(load_image('book-covers/'+random_className+\"/\"+file))\n",
        "                train_labels.append(random_index)\n",
        "                filesAndClassMap[random_className].pop(0)\n",
        "        if isEmpty(filesAndClassMap[random_className]):\n",
        "            class_names.pop(random_index)\n",
        "            print(\"No Of Classes to Process=\"+str(len(class_names)))\n",
        "        \n",
        "load_images()\n",
        "\n",
        "print(len(train_images))\n",
        "np.savez('dataset',train_images)\n",
        "np.savez('labels',train_labels)\n",
        " \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dsyu-gIfaVQt",
        "colab_type": "text"
      },
      "source": [
        "**Training CNN Model using the Loaded Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "trusted": true,
        "id": "mb8bDyyP96rH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd \n",
        "import os\n",
        "from keras.preprocessing.image import load_img\n",
        "from keras.preprocessing.image import img_to_array\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "import matplotlib.pyplot as pyplot\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.optimizers import SGD,rmsprop\n",
        "from random import randrange\n",
        "from datetime import datetime\n",
        "from packaging import version\n",
        "from keras import regularizers\n",
        "\n",
        "#Decompressing and loading dataset and labels\n",
        "images_compressed=np.load('dataset.npz')\n",
        "labels_compressed=np.load('labels.npz')\n",
        "images=images_compressed.f.arr_0\n",
        "labels=labels_compressed.f.arr_0\n",
        "\n",
        "#Fetching categories\n",
        "class_names=[]\n",
        "for root, dirname, filenames in os.walk('book-covers'):\n",
        "    for className in dirname:\n",
        "        class_names.append(className)\n",
        "\n",
        "class_names=class_names[0:5]\n",
        "print(class_names)\n",
        "\n",
        "#Plotting first 25 images for checking the images and labels\n",
        "def plot_images(images,labels):\n",
        "    pyplot.figure(figsize=(10,10))\n",
        "    for i in range(25):\n",
        "        pyplot.subplot(5,5,i+1)\n",
        "        pyplot.xticks([])\n",
        "        pyplot.yticks([])\n",
        "        pyplot.grid(False)\n",
        "        pyplot.imshow(images[i], cmap=pyplot.cm.binary)    \n",
        "        pyplot.xlabel(class_names[labels[i]])\n",
        "    pyplot.show()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#splitting into training and test sets\n",
        "train_images=images[500:,:,:,:]\n",
        "train_labels=labels[500:]\n",
        "test_images=images[0:500,:,:,:]\n",
        "test_labels=labels[0:500]\n",
        "\n",
        "plot_images(train_images,train_labels)\n",
        "\n",
        "\n",
        "#if book belongs to i th class the [0,0....i th index will be 1....0,0,0]\n",
        "import numpy as np\n",
        "def output_labels(x):\n",
        "  output=np.zeros((len(x),5))\n",
        "  for idx,val in enumerate(x):\n",
        "    output[idx][val]=1               \n",
        "  return output\n",
        "\n",
        "test_labels=output_labels(test_labels)\n",
        "train_labels=output_labels(train_labels)\n",
        "\n",
        "# Convolutional neural network setup\n",
        "def cnn_model():\n",
        "  model = models.Sequential()\n",
        "  model.add(tf.keras.applications.resnet.ResNet50(include_top=False, weights='imagenet', input_tensor=None, input_shape=(224,224,3), pooling=None))\n",
        "  model.add(layers.Flatten())\n",
        "  model.add(layers.Dense(128, activation='relu'))\n",
        "  model.add(layers.Dense(5, activation='softmax'))\n",
        "  opt = tf.keras.optimizers.RMSprop(lr=0.001, decay=1e-6)\n",
        "  model.compile(optimizer=opt,loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "  model.summary()\n",
        "  return model\n",
        "\n",
        "#Plotting accuracy and losslossm against epoch\n",
        "def model_diagonosis(history):\n",
        "  # plot loss\n",
        "\tpyplot.subplot(211)\n",
        "\tpyplot.title('Cross Entropy Loss')\n",
        "\tpyplot.plot(history.history['loss'], color='blue', label='train')\n",
        "\tpyplot.plot(history.history['val_loss'], color='orange', label='test')\n",
        "\t# plot accuracy\n",
        "\tpyplot.subplot(212)\n",
        "\tpyplot.title('Classification Accuracy')\n",
        "\tpyplot.plot(history.history['accuracy'], color='blue', label='train')\n",
        "\tpyplot.plot(history.history['val_accuracy'], color='orange', label='test')\n",
        " \n",
        "\n",
        "#Training and saving the model for future use.\n",
        "def training_model():\n",
        "  with tf.device('/device:GPU:0'):\n",
        "    model=cnn_model()\n",
        "    logdir=\"logs/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)\n",
        "    datagen = ImageDataGenerator(width_shift_range=0.1,height_shift_range=0.1,horizontal_flip=True)\n",
        "    it_train = datagen.flow(train_images,train_labels,batch_size=64)\n",
        "    history = model.fit(train_images,train_labels,epochs=50, validation_data=(test_images, test_labels), verbose=2,callbacks=[tensorboard_callback])\n",
        "    _,accuracy=model.evaluate(test_images,test_labels,verbose=2)\n",
        "    print('> %.3f' % (accuracy * 100.0))\n",
        "    model_diagonosis(history)\n",
        "    model.save('computed_model.h5')\n",
        "  \n",
        "training_model()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zf1wQV0kanSV",
        "colab_type": "text"
      },
      "source": [
        "**Mounting Google Drive onto the Colab Platform**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lsnPWwHDwSX_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Mounting google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dOXLIsYvav_t",
        "colab_type": "text"
      },
      "source": [
        "**Loading computed CNN model, providing sample input image and generating the output**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xtsUZQrmBREr",
        "colab_type": "code",
        "outputId": "a4f82764-fde5-4c30-bede-a8c4322e1a7c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "from numpy import loadtxt\n",
        "from keras.models import load_model\n",
        "from keras.preprocessing.image import load_img\n",
        "from keras.preprocessing.image import img_to_array\n",
        "import tensorflow as tf\n",
        "\n",
        "def load_image(filename):\n",
        "    img = load_img(filename, target_size=(224, 224))\n",
        "    img = img_to_array(img)\n",
        "    img = img.reshape(1, 224, 224, 3)\n",
        "    img = img.astype('float32')\n",
        "    img = img / 255.0\n",
        "    return img\n",
        "    \n",
        "test_image = load_image(\"/content/drive/My Drive/sample images/sample3.jpg\")\n",
        "# load model\n",
        "model = tf.keras.models.load_model('/content/drive/My Drive/5 category model.h5')\n",
        "classes = model.predict(test_image)[0]\n",
        "labels=['Art-Photography', 'Crafts-Hobbies', 'Poetry-Drama', 'Science-Geography', 'Reference']\n",
        "for i in range(len(labels)):\n",
        "    print(labels[i]+\"---->%2.5f\" % (classes[i]*100))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Art-Photography---->0.32102\n",
            "Crafts-Hobbies---->0.02694\n",
            "Poetry-Drama---->99.62040\n",
            "Science-Geography---->0.01661\n",
            "Reference---->0.01503\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2c-Xv8KD-Uqf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Installing Kaggle.\n",
        "!pip install kaggle\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qsstTQhpMPEY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#setting up kaggle ennvironment.\n",
        "import json\n",
        "token = {\"username\":\"*******\",\"key\":\"********\"}\n",
        "with open('/root/.kaggle/kaggle.json', 'w') as file:\n",
        "    json.dump(token, file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wg5-0Ko2M6rH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Kaggle API calls for loading book cover dataset\n",
        "!chmod 600 /root/.kaggle/kaggle.json\n",
        "!kaggle datasets download -d lukaanicin/book-covers-dataset\n",
        "!unzip book-covers-dataset.zip\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}